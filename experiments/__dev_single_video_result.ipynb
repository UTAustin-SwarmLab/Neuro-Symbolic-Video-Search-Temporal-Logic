{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "from ns_vfs.common.utility import save_frames\n",
    "from ns_vfs.config.loader import load_config\n",
    "from ns_vfs.data.frame import BenchmarkLTLFrame, FramesofInterest\n",
    "from ns_vfs.frame_searcher import FrameSearcher\n",
    "from ns_vfs.model.vision.grounding_dino import GroundingDino\n",
    "from ns_vfs.processor.benchmark_video_processor import BenchmarkVideoFrameProcessor\n",
    "from ns_vfs.video_to_automaton import VideotoAutomaton\n",
    "from _common import get_available_benchmark_video, get_classification_score\n",
    "from ns_vfs.model.vision.yolo import Yolo \n",
    "from ns_vfs.common.utility import list_flatten, load_pickle_to_dict, save_dict_to_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "benchmark_frame_video_root_dir = Path(\n",
    "    \"/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video\"\n",
    ")\n",
    "benchmark_image_set_dir = [x for x in benchmark_frame_video_root_dir.iterdir() if x.is_dir()]\n",
    "cv_model_list = [\"yolo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltl_video_dir_set = [x for x in benchmark_image_set_dir[0].iterdir() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/Gprop2'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/prop1Uprop2'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/prop1&prop2'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/Fprop1')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltl_video_dir_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"surfboard\") U \"spoon\"_150_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"banana\" & \"keyboard\") U \"mouse\"_25_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"car\" & \"person\") U \"tie\"_125_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"scissors\" & \"book\") U \"backpack\"_25_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"skis\") U \"book\"_200_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"fork\" & \"cup\") U \"bicycle\"_75_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"sheep\" & \"cow\") U \"bottle\"_175_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"car\") U \"motorcycle\"_50_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"toilet\" & \"bottle\") U \"horse\"_75_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"bench\" & \"person\") U \"suitcase\"_100_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"skis\" & \"backpack\") U \"surfboard\"_200_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"laptop\" & \"suitcase\") U \"keyboard\"_125_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"cow\" & \"person\") U \"backpack\"_75_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"frisbee\" & \"dog\") U \"giraffe\"_100_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"tv\" & \"mouse\") U \"vase\"_75_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"surfboard\" & \"person\") U \"bus\"_100_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"truck\" & \"airplane\") U \"bench\"_50_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"truck\" & \"car\") U \"cow\"_100_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"chair\" & \"couch\") U \"tv\"_200_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"clock\" & \"couch\") U \"airplane\"_200_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"knife\" & \"carrot\") U \"keyboard\"_100_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"bowl\" & \"sink\") U \"sandwich\"_150_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"fork\" & \"apple\") U \"bed\"_25_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"sink\" & \"toilet\") U \"toaster\"_50_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"train\" & \"person\") U \"keyboard\"_175_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"snowboard\") U \"knife\"_50_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"suitcase\" & \"handbag\") U \"carrot\"_100_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"refrigerator\" & \"person\") U \"sink\"_75_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"refrigerator\" & \"microwave\") U \"cake\"_75_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"car\" & \"truck\") U \"backpack\"_75_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"laptop\" & \"bed\") U \"book\"_125_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"toothbrush\" & \"bottle\") U \"skateboard\"_25_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"elephant\" & \"person\") U \"mouse\"_175_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"chair\" & \"laptop\") U \"bowl\"_150_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"sheep\" & \"person\") U \"scissors\"_50_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"frisbee\") U \"bowl\"_175_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"car\" & \"person\") U \"remote\"_25_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"surfboard\") U \"laptop\"_125_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"motorcycle\") U \"bus\"_50_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"motorcycle\" & \"truck\") U \"refrigerator\"_25_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"car\" & \"person\") U \"bottle\"_50_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"donut\" & \"tv\") U \"toilet\"_125_0.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"umbrella\") U \"bear\"_150_4.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"car\" & \"person\") U \"bus\"_200_3.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"cow\" & \"person\") U \"pizza\"_175_1.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"bed\") U \"snowboard\"_25_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"person\" & \"frisbee\") U \"bottle\"_50_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"motorcycle\" & \"person\") U \"vase\"_75_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"kite\" & \"umbrella\") U \"bench\"_25_2.pkl'),\n",
       " PosixPath('/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/_validated_benchmark_video/coco/(prop1&prop2)Uprop3/benchmark_COCO_ltl_(\"boat\" & \"clock\") U \"couch\"_150_0.pkl')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_video_file_list = get_available_benchmark_video(ltl_video_dir_set[2])\n",
    "benchmark_video_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Taking a single benchmark video\n",
    "\"\"\"\n",
    "search_result_per_video = {}\n",
    "####################################################\n",
    "benchmark_video_file = benchmark_video_file_list[0]\n",
    "for cv_model in cv_model_list:\n",
    "    if cv_model == \"yolo\":\n",
    "        cv_detection_model = Yolo(config=config.YOLO,\n",
    "                                    weight_path=config.YOLO.YOLO_CHECKPOINT_PATH)\n",
    "    elif cv_model == \"grounding_dino\":\n",
    "        cv_detection_model = GroundingDino(\n",
    "                config=config.GROUNDING_DINO,\n",
    "                weight_path=config.GROUNDING_DINO.GROUNDING_DINO_CHECKPOINT_PATH,\n",
    "                config_path=config.GROUNDING_DINO.GROUNDING_DINO_CONFIG_PATH,\n",
    "            )\n",
    "    benchmark_video_processor = BenchmarkVideoFrameProcessor(\n",
    "        video_path=benchmark_video_file,\n",
    "        artifact_dir=config.VERSION_AND_PATH.ARTIFACTS_PATH)\n",
    "\n",
    "    benchmark_video: BenchmarkLTLFrame = benchmark_video_processor.benchmark_image_frames\n",
    "\n",
    "    video_automata_builder = VideotoAutomaton(\n",
    "        detector=cv_detection_model,\n",
    "        video_processor=benchmark_video_processor,\n",
    "        artifact_dir=config.VERSION_AND_PATH.ARTIFACTS_PATH,\n",
    "        proposition_set=benchmark_video.proposition,\n",
    "        save_annotation=False,  # TODO: Debug only\n",
    "        save_image=False,  # TODO: Debug only\n",
    "        ltl_formula=f\"P>=0.80 [{benchmark_video.ltl_formula}]\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    frame_sercher = FrameSearcher(\n",
    "        video_automata_builder=video_automata_builder,\n",
    "        video_processor=benchmark_video_processor,\n",
    "    )\n",
    "\n",
    "    frame_of_interest = frame_sercher.search()\n",
    "\n",
    "    search_result_per_video[\"benchmark_video\"] = benchmark_video\n",
    "    search_result_per_video[cv_model] = frame_of_interest\n",
    "\n",
    "# classification_metrics\n",
    "search_result_per_video = get_classification_score(search_result_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Taking a single benchmark video from ltl_video_dir_set\n",
    "\"\"\"\n",
    "result = {}\n",
    "search_result_per_video = {}\n",
    "####################################################\n",
    "for benchmark_video_file in benchmark_video_file_list[0:5]:\n",
    "    ltl_formula = benchmark_video_file.name.split(\".\")[0].split(\"_ltl_\")[-1]\n",
    "    #result[ltl_formula] = {}\n",
    "    for cv_model in cv_model_list:\n",
    "        if cv_model == \"yolo\":\n",
    "            cv_detection_model = Yolo(config=config.YOLO,\n",
    "                                        weight_path=config.YOLO.YOLO_CHECKPOINT_PATH)\n",
    "        elif cv_model == \"grounding_dino\":\n",
    "            cv_detection_model = GroundingDino(\n",
    "                    config=config.GROUNDING_DINO,\n",
    "                    weight_path=config.GROUNDING_DINO.GROUNDING_DINO_CHECKPOINT_PATH,\n",
    "                    config_path=config.GROUNDING_DINO.GROUNDING_DINO_CONFIG_PATH,\n",
    "                )\n",
    "        benchmark_video_processor = BenchmarkVideoFrameProcessor(\n",
    "            video_path=benchmark_video_file,\n",
    "            artifact_dir=config.VERSION_AND_PATH.ARTIFACTS_PATH)\n",
    "\n",
    "        benchmark_video: BenchmarkLTLFrame = benchmark_video_processor.benchmark_image_frames\n",
    "\n",
    "        video_automata_builder = VideotoAutomaton(\n",
    "            detector=cv_detection_model,\n",
    "            video_processor=benchmark_video_processor,\n",
    "            artifact_dir=config.VERSION_AND_PATH.ARTIFACTS_PATH,\n",
    "            proposition_set=benchmark_video.proposition,\n",
    "            save_annotation=False,  # TODO: Debug only\n",
    "            save_image=False,  # TODO: Debug only\n",
    "            ltl_formula=f\"P>=0.80 [{benchmark_video.ltl_formula}]\",\n",
    "            verbose=False,\n",
    "        )\n",
    "        frame_sercher = FrameSearcher(\n",
    "            video_automata_builder=video_automata_builder,\n",
    "            video_processor=benchmark_video_processor,\n",
    "        )\n",
    "\n",
    "        frame_of_interest = frame_sercher.search()\n",
    "\n",
    "        search_result_per_video[\"benchmark_video\"] = benchmark_video\n",
    "        search_result_per_video[cv_model] = frame_of_interest\n",
    "\n",
    "    # classification_metrics\n",
    "    search_result_per_video = get_classification_score(search_result_per_video)\n",
    "    result[ltl_formula] = search_result_per_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_pickle(result, path=\"/opt/Neuro-Symbolic-Video-Frame-Search/artifacts/\", file_name=\"test_result.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['F \"horse\"_25_2'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['F \"horse\"_25_2'][\"benchmark_video\"]\n",
    "print(result['F \"horse\"_25_2'][\"benchmark_video\"].number_of_frame)\n",
    "print(result['F \"horse\"_25_2'][\"benchmark_video\"].frames_of_interest)\n",
    "#print(result['F \"horse\"_25_2'][\"benchmark_video\"].labels_of_frames)\n",
    "#print(result['F \"horse\"_25_2'][\"benchmark_video\"].images_of_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['F \"horse\"_25_2'][\"grounding_dino\"]\n",
    "print(result['F \"horse\"_25_2'][\"grounding_dino\"].foi_list)\n",
    "# print(result['F \"horse\"_25_2'][\"grounding_dino\"].frame_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['F \"horse\"_25_2'][\"yolo\"]\n",
    "print(result['F \"horse\"_25_2'][\"yolo\"].foi_list)\n",
    "# print(result['F \"horse\"_25_2'][\"grounding_dino\"].frame_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['F \"horse\"_25_2'][\"grounding_dino_classification_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['F \"horse\"_25_2'][\"yolo_classification_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
